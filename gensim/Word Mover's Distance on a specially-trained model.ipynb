{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import json\n",
    "import pyemd\n",
    "import numpy as np\n",
    "import random\n",
    "import glob\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "from sklearn.metrics import euclidean_distances\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.utils import check_array\n",
    "from sklearn.cross_validation import check_cv\n",
    "from sklearn.metrics.scorer import check_scoring\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "import scipy\n",
    "\n",
    "from pyemd import emd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _pickle_method(method):\n",
    "\tfunc_name = method.im_func.__name__\n",
    "\tobj = method.im_self\n",
    "\tcls = method.im_class\n",
    "\tif func_name.startswith('__') and not func_name.endswith('__'): #deal with mangled names\n",
    "\t\tcls_name = cls.__name__.lstrip('_')\n",
    "\t\tfunc_name = '_' + cls_name + func_name\n",
    "\treturn _unpickle_method, (func_name, obj, cls)\n",
    "\n",
    "def _unpickle_method(func_name, obj, cls):\n",
    "\tfor cls in cls.__mro__:\n",
    "\t\ttry:\n",
    "\t\t\tfunc = cls.__dict__[func_name]\n",
    "\t\texcept KeyError:\n",
    "\t\t\tpass\n",
    "\t\telse:\n",
    "\t\t\tbreak\n",
    "\treturn func.__get__(obj, cls)\n",
    "\n",
    "import copy_reg\n",
    "import types\n",
    "\n",
    "copy_reg.pickle(types.MethodType, _pickle_method, _unpickle_method)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def do_census():\n",
    "    count = defaultdict(int)\n",
    "    json_paths = glob.glob('./*.json')\n",
    "    \n",
    "    for p in json_paths:\n",
    "        with open(p, 'r') as f:\n",
    "            count[p] = len(json.load(f))\n",
    "    return count\n",
    "\n",
    "def chunks(l, n):\n",
    "    \"\"\"Yield successive n-sized chunks from l.\"\"\"\n",
    "    for i in xrange(0, len(l), n):\n",
    "        yield l[i:i+n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class WordMoversKNN(KNeighborsClassifier):\n",
    "    \"\"\"K nearest neighbors classifier using the Word Mover's Distance.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    W_embed : array, shape: (vocab_size, embed_size)\n",
    "        Precomputed word embeddings between vocabulary items.\n",
    "        Row indices should correspond to the columns in the bag-of-words input.\n",
    "\n",
    "    n_neighbors : int, optional (default = 5)\n",
    "        Number of neighbors to use by default for :meth:`k_neighbors` queries.\n",
    "\n",
    "    n_jobs : int, optional (default = 1)\n",
    "        The number of parallel jobs to run for Word Mover's Distance computation.\n",
    "        If ``-1``, then the number of jobs is set to the number of CPU cores.\n",
    "    \n",
    "    verbose : int, optional\n",
    "        Controls the verbosity; the higher, the more messages. Defaults to 0.\n",
    "        \n",
    "    References\n",
    "    ----------\n",
    "    \n",
    "    Matt J. Kusner, Yu Sun, Nicholas I. Kolkin, Kilian Q. Weinberger\n",
    "    From Word Embeddings To Document Distances\n",
    "    The International Conference on Machine Learning (ICML), 2015\n",
    "    http://mkusner.github.io/publications/WMD.pdf\n",
    "    \n",
    "    \"\"\"\n",
    "    _pairwise = False\n",
    "\n",
    "    def __init__(self, W_embed, n_neighbors=1, n_jobs=1, verbose=False):\n",
    "        self.W_embed = W_embed\n",
    "        self.verbose = verbose\n",
    "        super(WordMoversKNN, self).__init__(n_neighbors=n_neighbors, n_jobs=n_jobs,\n",
    "                                            metric='precomputed', algorithm='auto')\n",
    "\n",
    "    def _wmd(self, i, row, X_train):\n",
    "        \"\"\"Compute the WMD between training sample i and given test row.\n",
    "        \n",
    "        Assumes that `row` and train samples are sparse BOW vectors summing to 1.\n",
    "        \"\"\"\n",
    "        union_idx = np.union1d(X_train[i].indices, row.indices)\n",
    "        W_minimal = self.W_embed[union_idx]\n",
    "        W_dist = euclidean_distances(W_minimal)\n",
    "        bow_i = X_train[i, union_idx].A.ravel()\n",
    "        bow_j = row[:, union_idx].A.ravel()\n",
    "        return emd(bow_i, bow_j, W_dist)\n",
    "    \n",
    "    def _wmd_row(self, row, X_train):\n",
    "        \"\"\"Wrapper to compute the WMD of a row with all training samples.\n",
    "        \n",
    "        Assumes that `row` and train samples are sparse BOW vectors summing to 1.\n",
    "        Useful for parallelization.\n",
    "        \"\"\"\n",
    "        n_samples_train = X_train.shape[0]\n",
    "        return [self._wmd(i, row, X_train) for i in range(n_samples_train)]\n",
    "\n",
    "    def _pairwise_wmd(self, X_test, X_train=None):\n",
    "        \"\"\"Computes the word mover's distance between all train and test points.\n",
    "        \n",
    "        Parallelized over rows of X_test.\n",
    "        \n",
    "        Assumes that train and test samples are sparse BOW vectors summing to 1.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X_test: scipy.sparse matrix, shape: (n_test_samples, vocab_size)\n",
    "            Test samples.\n",
    "        \n",
    "        X_train: scipy.sparse matrix, shape: (n_train_samples, vocab_size)\n",
    "            Training samples. If `None`, uses the samples the estimator was fit with.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        dist : array, shape: (n_test_samples, n_train_samples)\n",
    "            Distances between all test samples and all train samples.\n",
    "        \n",
    "        \"\"\"\n",
    "        n_samples_test = X_test.shape[0]\n",
    "        \n",
    "        if X_train is None:\n",
    "            X_train = self._fit_X\n",
    "\n",
    "        dist = Parallel(n_jobs=self.n_jobs, verbose=self.verbose)(delayed(self._wmd_row)(test_sample, X_train) for test_sample in X_test)\n",
    "        # dist = [self._wmd_row(test_sample, X_train) for test_sample in X_test]\n",
    "        return np.array(dist)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit the model using X as training data and y as target values\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : scipy sparse matrix, shape: (n_samples, n_features)\n",
    "            Training data. \n",
    "\n",
    "        y : {array-like, sparse matrix}\n",
    "            Target values of shape = [n_samples] or [n_samples, n_outputs]\n",
    "\n",
    "        \"\"\"\n",
    "        X = check_array(X, accept_sparse='csr', copy=True)\n",
    "        X = normalize(X, norm='l1', copy=False)\n",
    "        return super(WordMoversKNN, self).fit(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict the class labels for the provided data\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : scipy.sparse matrix, shape (n_test_samples, vocab_size)\n",
    "            Test samples.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        y : array of shape [n_samples]\n",
    "            Class labels for each data sample.\n",
    "        \"\"\"\n",
    "        X = check_array(X, accept_sparse='csr', copy=True)\n",
    "        X = normalize(X, norm='l1', copy=False)\n",
    "        dist = self._pairwise_wmd(X)\n",
    "        return super(WordMoversKNN, self).predict(dist)\n",
    "    \n",
    "    \n",
    "class WordMoversKNNCV(WordMoversKNN):\n",
    "    \"\"\"Cross-validated KNN classifier using the Word Mover's Distance.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    W_embed : array, shape: (vocab_size, embed_size)\n",
    "        Precomputed word embeddings between vocabulary items.\n",
    "        Row indices should correspond to the columns in the bag-of-words input.\n",
    "\n",
    "    n_neighbors_try : sequence, optional\n",
    "        List of ``n_neighbors`` values to try.\n",
    "        If None, tries 1-5 neighbors.\n",
    "\n",
    "    scoring : string, callable or None, optional, default: None\n",
    "        A string (see model evaluation documentation) or\n",
    "        a scorer callable object / function with signature\n",
    "        ``scorer(estimator, X, y)``.\n",
    "\n",
    "    cv : int, cross-validation generator or an iterable, optional\n",
    "        Determines the cross-validation splitting strategy.\n",
    "        Possible inputs for cv are:\n",
    "          - None, to use the default 3-fold cross-validation,\n",
    "          - integer, to specify the number of folds.\n",
    "          - An object to be used as a cross-validation generator.\n",
    "          - An iterable yielding train/test splits.\n",
    "        For integer/None inputs, StratifiedKFold is used.\n",
    "\n",
    "    n_jobs : int, optional (default = 1)\n",
    "        The number of parallel jobs to run for Word Mover's Distance computation.\n",
    "        If ``-1``, then the number of jobs is set to the number of CPU cores.\n",
    "\n",
    "    verbose : int, optional\n",
    "        Controls the verbosity; the higher, the more messages. Defaults to 0.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    cv_scores_ : array, shape (n_folds, len(n_neighbors_try))\n",
    "        Test set scores for each fold.\n",
    "\n",
    "    n_neighbors_ : int,\n",
    "        The best `n_neighbors` value found.\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "\n",
    "    Matt J. Kusner, Yu Sun, Nicholas I. Kolkin, Kilian Q. Weinberger\n",
    "    From Word Embeddings To Document Distances\n",
    "    The International Conference on Machine Learning (ICML), 2015\n",
    "    http://mkusner.github.io/publications/WMD.pdf\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, W_embed, n_neighbors_try=None, scoring=None, cv=3,\n",
    "                 n_jobs=1, verbose=False):\n",
    "        self.cv = cv\n",
    "        self.n_neighbors_try = n_neighbors_try\n",
    "        self.scoring = scoring\n",
    "        super(WordMoversKNNCV, self).__init__(W_embed,\n",
    "                                              n_neighbors=None,\n",
    "                                              n_jobs=n_jobs,\n",
    "                                              verbose=verbose)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit KNN model by choosing the best `n_neighbors`.\n",
    "        \n",
    "        Parameters\n",
    "        -----------\n",
    "        X : scipy.sparse matrix, (n_samples, vocab_size)\n",
    "            Data\n",
    "        y : ndarray, shape (n_samples,) or (n_samples, n_targets)\n",
    "            Target\n",
    "        \"\"\"\n",
    "        if self.n_neighbors_try is None:\n",
    "            n_neighbors_try = range(1, 6)\n",
    "        else:\n",
    "            n_neighbors_try = self.n_neighbors_try\n",
    "\n",
    "        X = check_array(X, accept_sparse='csr', copy=True)\n",
    "        X = normalize(X, norm='l1', copy=False)\n",
    "\n",
    "        cv = check_cv(self.cv, X, y)\n",
    "        knn = KNeighborsClassifier(metric='precomputed', algorithm='auto')\n",
    "        scorer = check_scoring(knn, scoring=self.scoring)\n",
    "\n",
    "        scores = []\n",
    "        for train_ix, test_ix in cv:\n",
    "            dist = self._pairwise_wmd(X[test_ix], X[train_ix])\n",
    "            knn.fit(X[train_ix], y[train_ix])\n",
    "            scores.append([\n",
    "                scorer(knn.set_params(n_neighbors=k), dist, y[test_ix])\n",
    "                for k in n_neighbors_try\n",
    "            ])\n",
    "        scores = np.array(scores)\n",
    "        self.cv_scores_ = scores\n",
    "\n",
    "        best_k_ix = np.argmax(np.mean(scores, axis=0))\n",
    "        best_k = n_neighbors_try[best_k_ix]\n",
    "        self.n_neighbors = self.n_neighbors_ = best_k\n",
    "\n",
    "        return super(WordMoversKNNCV, self).fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# census = do_census()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'census' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-3f23929d69f4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcensus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcensus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'census' is not defined"
     ]
    }
   ],
   "source": [
    "sorted(dict(census), key=census.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_labels = ['Mozart', 'Bach', 'Beethoven', 'Haydn', 'Telemann']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "documents_labeled = []\n",
    "\n",
    "for class_number, composer in enumerate(class_labels):\n",
    "    with open(\"{}.json\".format(composer), 'r') as f:\n",
    "        docs = json.load(f)\n",
    "    \n",
    "    for doc in docs:\n",
    "        documents_labeled.append((doc, class_number))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(documents_labeled)\n",
    "random.shuffle(documents_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = documents_labeled[:1000]\n",
    "test = documents_labeled[1000:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for_embedding = [x[0] for x in train + test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(for_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences = []\n",
    "\n",
    "for doc in for_embedding:\n",
    "    sentences.extend([x for x in chunks(doc, 32)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 48s, sys: 710 ms, total: 2min 49s\n",
      "Wall time: 1min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = gensim.models.Word2Vec(sentences, size=100, window=5, min_count=5, workers=2, sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W = model.syn0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1516, 100)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_signature(doc, common_vocab):\n",
    "    c = Counter(doc)\n",
    "    signature = []\n",
    "    \n",
    "    for w in common_vocab:\n",
    "        count = c.get(w, 0)\n",
    "        signature.append(count)\n",
    "    \n",
    "    s_array = np.asarray(signature)\n",
    "    s_array = s_array.astype(np.double)\n",
    "    s_array /= s_array.sum()\n",
    "    \n",
    "    return s_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_sigs = [get_signature(d[0], model.index2word) for d in train]\n",
    "test_sigs = [get_signature(d[0], model.index2word) for d in test]\n",
    "\n",
    "train_labels = [d[1] for d in train] \n",
    "test_labels = [d[1] for d in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_array = np.asarray(train_sigs)\n",
    "train_array = train_array.astype(np.float64)\n",
    "train_array = scipy.sparse.csr_matrix(train_array)\n",
    "\n",
    "test_array = np.asarray(test_sigs)\n",
    "test_array = test_array.astype(np.float64)\n",
    "test_array = scipy.sparse.csr_matrix(test_array)\n",
    "\n",
    "W = W.astype(np.float64)\n",
    "W = scipy.sparse.csr_matrix(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wmknn_classifier = WordMoversKNN(W, verbose=5,n_jobs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 1516), 1000)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_array.shape, len(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fitted = wmknn_classifier.fit(train_array, train_labels)\n",
    "scores = fitted.score(test_array[:10], test_labels[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'W' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-b27fba9101e2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m knn_cv = WordMoversKNNCV(cv=3,\n\u001b[0;32m      2\u001b[0m                          \u001b[0mn_neighbors_try\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m                          W_embed=W, verbose=5, n_jobs=3)\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'W' is not defined"
     ]
    }
   ],
   "source": [
    "knn_cv = WordMoversKNNCV(cv=3,\n",
    "                         n_neighbors_try=range(1, 5),\n",
    "                         W_embed=W, verbose=5, n_jobs=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
